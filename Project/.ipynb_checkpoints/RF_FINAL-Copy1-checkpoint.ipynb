{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4ec887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abed08",
   "metadata": {},
   "source": [
    "# Step 1: Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052f631",
   "metadata": {},
   "source": [
    "#### Reading the sensor data from dataset provided in '.csv' format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502ef223",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data=pd.read_csv('sensor.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2cd3a",
   "metadata": {},
   "source": [
    "#### Display data features & their associated datatypes inorder to take processing decision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b1a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220320 entries, 0 to 220319\n",
      "Data columns (total 55 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Unnamed: 0      220320 non-null  int64  \n",
      " 1   timestamp       220320 non-null  object \n",
      " 2   sensor_00       210112 non-null  float64\n",
      " 3   sensor_01       219951 non-null  float64\n",
      " 4   sensor_02       220301 non-null  float64\n",
      " 5   sensor_03       220301 non-null  float64\n",
      " 6   sensor_04       220301 non-null  float64\n",
      " 7   sensor_05       220301 non-null  float64\n",
      " 8   sensor_06       215522 non-null  float64\n",
      " 9   sensor_07       214869 non-null  float64\n",
      " 10  sensor_08       215213 non-null  float64\n",
      " 11  sensor_09       215725 non-null  float64\n",
      " 12  sensor_10       220301 non-null  float64\n",
      " 13  sensor_11       220301 non-null  float64\n",
      " 14  sensor_12       220301 non-null  float64\n",
      " 15  sensor_13       220301 non-null  float64\n",
      " 16  sensor_14       220299 non-null  float64\n",
      " 17  sensor_15       0 non-null       float64\n",
      " 18  sensor_16       220289 non-null  float64\n",
      " 19  sensor_17       220274 non-null  float64\n",
      " 20  sensor_18       220274 non-null  float64\n",
      " 21  sensor_19       220304 non-null  float64\n",
      " 22  sensor_20       220304 non-null  float64\n",
      " 23  sensor_21       220304 non-null  float64\n",
      " 24  sensor_22       220279 non-null  float64\n",
      " 25  sensor_23       220304 non-null  float64\n",
      " 26  sensor_24       220304 non-null  float64\n",
      " 27  sensor_25       220284 non-null  float64\n",
      " 28  sensor_26       220300 non-null  float64\n",
      " 29  sensor_27       220304 non-null  float64\n",
      " 30  sensor_28       220304 non-null  float64\n",
      " 31  sensor_29       220248 non-null  float64\n",
      " 32  sensor_30       220059 non-null  float64\n",
      " 33  sensor_31       220304 non-null  float64\n",
      " 34  sensor_32       220252 non-null  float64\n",
      " 35  sensor_33       220304 non-null  float64\n",
      " 36  sensor_34       220304 non-null  float64\n",
      " 37  sensor_35       220304 non-null  float64\n",
      " 38  sensor_36       220304 non-null  float64\n",
      " 39  sensor_37       220304 non-null  float64\n",
      " 40  sensor_38       220293 non-null  float64\n",
      " 41  sensor_39       220293 non-null  float64\n",
      " 42  sensor_40       220293 non-null  float64\n",
      " 43  sensor_41       220293 non-null  float64\n",
      " 44  sensor_42       220293 non-null  float64\n",
      " 45  sensor_43       220293 non-null  float64\n",
      " 46  sensor_44       220293 non-null  float64\n",
      " 47  sensor_45       220293 non-null  float64\n",
      " 48  sensor_46       220293 non-null  float64\n",
      " 49  sensor_47       220293 non-null  float64\n",
      " 50  sensor_48       220293 non-null  float64\n",
      " 51  sensor_49       220293 non-null  float64\n",
      " 52  sensor_50       143303 non-null  float64\n",
      " 53  sensor_51       204937 non-null  float64\n",
      " 54  machine_status  220320 non-null  object \n",
      "dtypes: float64(52), int64(1), object(2)\n",
      "memory usage: 92.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sensor_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac218ebf",
   "metadata": {},
   "source": [
    "#### Understanding the flow of values of each feature in the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac7afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_42</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220320.000000</td>\n",
       "      <td>210112.000000</td>\n",
       "      <td>219951.000000</td>\n",
       "      <td>220301.000000</td>\n",
       "      <td>220301.000000</td>\n",
       "      <td>220301.000000</td>\n",
       "      <td>220301.000000</td>\n",
       "      <td>215522.000000</td>\n",
       "      <td>214869.000000</td>\n",
       "      <td>215213.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>220293.000000</td>\n",
       "      <td>143303.000000</td>\n",
       "      <td>204937.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110159.500000</td>\n",
       "      <td>2.372221</td>\n",
       "      <td>47.591611</td>\n",
       "      <td>50.867392</td>\n",
       "      <td>43.752481</td>\n",
       "      <td>590.673936</td>\n",
       "      <td>73.396414</td>\n",
       "      <td>13.501537</td>\n",
       "      <td>15.843152</td>\n",
       "      <td>15.200721</td>\n",
       "      <td>...</td>\n",
       "      <td>35.453455</td>\n",
       "      <td>43.879591</td>\n",
       "      <td>42.656877</td>\n",
       "      <td>43.094984</td>\n",
       "      <td>48.018585</td>\n",
       "      <td>44.340903</td>\n",
       "      <td>150.889044</td>\n",
       "      <td>57.119968</td>\n",
       "      <td>183.049260</td>\n",
       "      <td>202.699667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>63601.049991</td>\n",
       "      <td>0.412227</td>\n",
       "      <td>3.296666</td>\n",
       "      <td>3.666820</td>\n",
       "      <td>2.418887</td>\n",
       "      <td>144.023912</td>\n",
       "      <td>17.298247</td>\n",
       "      <td>2.163736</td>\n",
       "      <td>2.201155</td>\n",
       "      <td>2.037390</td>\n",
       "      <td>...</td>\n",
       "      <td>10.259521</td>\n",
       "      <td>11.044404</td>\n",
       "      <td>11.576355</td>\n",
       "      <td>12.837520</td>\n",
       "      <td>15.641284</td>\n",
       "      <td>10.442437</td>\n",
       "      <td>82.244957</td>\n",
       "      <td>19.143598</td>\n",
       "      <td>65.258650</td>\n",
       "      <td>109.588607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.159720</td>\n",
       "      <td>31.640620</td>\n",
       "      <td>2.798032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>...</td>\n",
       "      <td>22.135416</td>\n",
       "      <td>24.479166</td>\n",
       "      <td>25.752316</td>\n",
       "      <td>26.331018</td>\n",
       "      <td>26.331018</td>\n",
       "      <td>27.199070</td>\n",
       "      <td>26.331018</td>\n",
       "      <td>26.620370</td>\n",
       "      <td>27.488426</td>\n",
       "      <td>27.777779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55079.750000</td>\n",
       "      <td>2.438831</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>50.390620</td>\n",
       "      <td>42.838539</td>\n",
       "      <td>626.620400</td>\n",
       "      <td>69.976260</td>\n",
       "      <td>13.346350</td>\n",
       "      <td>15.907120</td>\n",
       "      <td>15.183740</td>\n",
       "      <td>...</td>\n",
       "      <td>32.812500</td>\n",
       "      <td>39.583330</td>\n",
       "      <td>36.747684</td>\n",
       "      <td>36.747684</td>\n",
       "      <td>40.509258</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>83.912030</td>\n",
       "      <td>47.743060</td>\n",
       "      <td>167.534700</td>\n",
       "      <td>179.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110159.500000</td>\n",
       "      <td>2.456539</td>\n",
       "      <td>48.133678</td>\n",
       "      <td>51.649300</td>\n",
       "      <td>44.227428</td>\n",
       "      <td>632.638916</td>\n",
       "      <td>75.576790</td>\n",
       "      <td>13.642940</td>\n",
       "      <td>16.167530</td>\n",
       "      <td>15.494790</td>\n",
       "      <td>...</td>\n",
       "      <td>35.156250</td>\n",
       "      <td>42.968750</td>\n",
       "      <td>40.509260</td>\n",
       "      <td>40.219910</td>\n",
       "      <td>44.849540</td>\n",
       "      <td>42.534720</td>\n",
       "      <td>138.020800</td>\n",
       "      <td>52.662040</td>\n",
       "      <td>193.865700</td>\n",
       "      <td>197.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>165239.250000</td>\n",
       "      <td>2.499826</td>\n",
       "      <td>49.479160</td>\n",
       "      <td>52.777770</td>\n",
       "      <td>45.312500</td>\n",
       "      <td>637.615723</td>\n",
       "      <td>80.912150</td>\n",
       "      <td>14.539930</td>\n",
       "      <td>16.427950</td>\n",
       "      <td>15.697340</td>\n",
       "      <td>...</td>\n",
       "      <td>36.979164</td>\n",
       "      <td>46.614580</td>\n",
       "      <td>45.138890</td>\n",
       "      <td>44.849540</td>\n",
       "      <td>51.215280</td>\n",
       "      <td>46.585650</td>\n",
       "      <td>208.333300</td>\n",
       "      <td>60.763890</td>\n",
       "      <td>219.907400</td>\n",
       "      <td>216.724500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>220319.000000</td>\n",
       "      <td>2.549016</td>\n",
       "      <td>56.727430</td>\n",
       "      <td>56.032990</td>\n",
       "      <td>48.220490</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>99.999880</td>\n",
       "      <td>22.251160</td>\n",
       "      <td>23.596640</td>\n",
       "      <td>24.348960</td>\n",
       "      <td>...</td>\n",
       "      <td>374.218800</td>\n",
       "      <td>408.593700</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>320.312500</td>\n",
       "      <td>370.370400</td>\n",
       "      <td>303.530100</td>\n",
       "      <td>561.632000</td>\n",
       "      <td>464.409700</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0      sensor_00      sensor_01      sensor_02  \\\n",
       "count  220320.000000  210112.000000  219951.000000  220301.000000   \n",
       "mean   110159.500000       2.372221      47.591611      50.867392   \n",
       "std     63601.049991       0.412227       3.296666       3.666820   \n",
       "min         0.000000       0.000000       0.000000      33.159720   \n",
       "25%     55079.750000       2.438831      46.310760      50.390620   \n",
       "50%    110159.500000       2.456539      48.133678      51.649300   \n",
       "75%    165239.250000       2.499826      49.479160      52.777770   \n",
       "max    220319.000000       2.549016      56.727430      56.032990   \n",
       "\n",
       "           sensor_03      sensor_04      sensor_05      sensor_06  \\\n",
       "count  220301.000000  220301.000000  220301.000000  215522.000000   \n",
       "mean       43.752481     590.673936      73.396414      13.501537   \n",
       "std         2.418887     144.023912      17.298247       2.163736   \n",
       "min        31.640620       2.798032       0.000000       0.014468   \n",
       "25%        42.838539     626.620400      69.976260      13.346350   \n",
       "50%        44.227428     632.638916      75.576790      13.642940   \n",
       "75%        45.312500     637.615723      80.912150      14.539930   \n",
       "max        48.220490     800.000000      99.999880      22.251160   \n",
       "\n",
       "           sensor_07      sensor_08  ...      sensor_42      sensor_43  \\\n",
       "count  214869.000000  215213.000000  ...  220293.000000  220293.000000   \n",
       "mean       15.843152      15.200721  ...      35.453455      43.879591   \n",
       "std         2.201155       2.037390  ...      10.259521      11.044404   \n",
       "min         0.000000       0.028935  ...      22.135416      24.479166   \n",
       "25%        15.907120      15.183740  ...      32.812500      39.583330   \n",
       "50%        16.167530      15.494790  ...      35.156250      42.968750   \n",
       "75%        16.427950      15.697340  ...      36.979164      46.614580   \n",
       "max        23.596640      24.348960  ...     374.218800     408.593700   \n",
       "\n",
       "           sensor_44      sensor_45      sensor_46      sensor_47  \\\n",
       "count  220293.000000  220293.000000  220293.000000  220293.000000   \n",
       "mean       42.656877      43.094984      48.018585      44.340903   \n",
       "std        11.576355      12.837520      15.641284      10.442437   \n",
       "min        25.752316      26.331018      26.331018      27.199070   \n",
       "25%        36.747684      36.747684      40.509258      39.062500   \n",
       "50%        40.509260      40.219910      44.849540      42.534720   \n",
       "75%        45.138890      44.849540      51.215280      46.585650   \n",
       "max      1000.000000     320.312500     370.370400     303.530100   \n",
       "\n",
       "           sensor_48      sensor_49      sensor_50      sensor_51  \n",
       "count  220293.000000  220293.000000  143303.000000  204937.000000  \n",
       "mean      150.889044      57.119968     183.049260     202.699667  \n",
       "std        82.244957      19.143598      65.258650     109.588607  \n",
       "min        26.331018      26.620370      27.488426      27.777779  \n",
       "25%        83.912030      47.743060     167.534700     179.108800  \n",
       "50%       138.020800      52.662040     193.865700     197.338000  \n",
       "75%       208.333300      60.763890     219.907400     216.724500  \n",
       "max       561.632000     464.409700    1000.000000    1000.000000  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5c913",
   "metadata": {},
   "source": [
    "#### Analyzing percentage of null data within each feature branch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data=sensor_data.iloc[:,2:-1].isna().sum()/sensor_data.shape[0] # #_null_vlaues_per_column/total_#_data_point\n",
    "x=np.arange(0,52)\n",
    "y=np.array(null_data)\n",
    "fig=plt.figure(num=None, figsize=(16, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xticks(x)\n",
    "plt.bar(x,y)\n",
    "plt.title('percentage of null value contained by each sensor')\n",
    "plt.xlabel('sensors')\n",
    "plt.ylabel('percent null values')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('NA values per sensor in percent:\\n',null_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12432339",
   "metadata": {},
   "source": [
    "#### Droping columns which is completely holds NULL value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data.drop(['sensor_15','Unnamed: 0'],inplace=True,axis=1)#removing column 'sensor_15' because it has all null value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8250e",
   "metadata": {},
   "source": [
    "Here we are going to calculate the target class 'machine_status' under seperate unique labels to understand the relationship of sensors with three different values such as 'BROKEN', 'RECOVERING' & 'NORMAL':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7969d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating group to analyze target classes\n",
    "grouped_data =sensor_data.groupby('machine_status') \n",
    "x=np.arange(0,52)\n",
    "\n",
    "# Calculating mean for each group\n",
    "dm=grouped_data.mean() \n",
    "\n",
    "# Plotting machine_status group data against their mean values to understand the deviation\n",
    "fig=plt.figure(num=None, figsize=(16, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xticks(x)\n",
    "plt.plot(x[0:15],dm.loc['BROKEN'].values[0:15],label='BROKEN',c='r') #plot mean for 0 to 15 sensor, we show absent of sensor_15 we plot data in parts.\n",
    "plt.plot(x[16:],dm.loc['BROKEN'].values[15:],c='r')\n",
    "plt.plot(x[0:15],dm.loc['NORMAL'].values[0:15],label='NORMAL',c='g')\n",
    "plt.plot(x[16:],dm.loc['NORMAL'].values[15:],c='g')\n",
    "plt.plot(x[0:15],dm.loc['RECOVERING'].values[0:15],label='RECOVERING',c='y')\n",
    "plt.plot(x[16:],dm.loc['RECOVERING'].values[15:],c='y')\n",
    "plt.legend()\n",
    "plt.xlabel('sensor number(sensor_0,sensor_1...)')\n",
    "plt.ylabel('mean of sensor')\n",
    "plt.title('mean of sensors among class labels')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ce12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean deviation plot for comparing Broken vs Normal difference analysis\n",
    "diff=dict()\n",
    "for col in dm.columns:\n",
    "    diff[col]=abs(dm[col][0]-dm[col][1])\n",
    "\n",
    "fig=plt.figure(num=None, figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "a = fig.add_subplot(1, 1, 1)\n",
    "a.set_xticks(x)\n",
    "plt.plot(x[0:15],list(diff.values())[0:15],c='r')\n",
    "plt.plot(x[16:],list(diff.values())[15:],c='r')\n",
    "plt.grid()\n",
    "plt.xlabel('Sensor 1,2,3,4,5....')\n",
    "plt.ylabel('Mean difference b/w \"BROKEN\" and \"NORMAL\"')\n",
    "plt.title('Mean Deviation Analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling up 'NaN' values with sensor data median values\n",
    "sensor_data = sensor_data.fillna(sensor_data.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing target set \"machine_status\" with scalar values to predict outcomes\n",
    "# -> NORMAL = 0 -> BROKEN = 1  -> RECOVERING = 1\n",
    "sensor_data['machine_status'].replace({'NORMAL' : 0,'BROKEN' : 1,'RECOVERING' : 1},inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddb29b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting histogram for every sensor data to understand the effect of outliers on this data set\n",
    "sensor_data.hist(figsize=(20,20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184e0d7",
   "metadata": {},
   "source": [
    "From the following bar plot data we can uncderstand that there is larger imbalance in the data. From the given plot it is understood that pump is in 'NORMAL' condition for most part. Since 'RECOVERING' mean breakdown in operation we consider 'BROKEN' & 'RECOVERING' class equal everytime, there is not much difference between these two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data['machine_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = sensor_data['machine_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e906fd5",
   "metadata": {},
   "source": [
    "- Based on various results collected previously, I decided to drop few sensor data features inorder to maintain consistency in the data flow.Highly unclean data would be a great challenge to create prediction algorithm in this challenging dataset.\n",
    "\n",
    "- As few sensor features mentioned in the following program are dropped due to the fact that the values generated by these sensor are not consistent & there was a huge difference from their mean value. Hence its considered that these sensors posses negative sound to noise ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data.drop(['sensor_01','sensor_03','sensor_14','sensor_16','sensor_17','sensor_18','sensor_19','sensor_20','sensor_21',\n",
    "           'sensor_22','sensor_23','sensor_24','sensor_25','sensor_26','sensor_27','sensor_28','sensor_29','sensor_30',\n",
    "           'sensor_31','sensor_33','sensor_34','sensor_37','sensor_36','sensor_48'],\n",
    "          inplace=True,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f51d6",
   "metadata": {},
   "source": [
    "### Preparing our customized dataframe with rolling window strategy:  \n",
    "- Each window we are going to take min, max, standerd deviation, midian and mean.\n",
    "- We are using window of 10 samples and predict failure before 5 minutes\n",
    "- We are using window spacing of 1\n",
    "- If samples are like s1,s2,s3....... then 1st window is s1 - s10 and 2nd should be s2-s11 and so on. \n",
    "- Windows are continuous rolling window which means we are not dropping any part of the dataset during modeling or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe feature based on median, mean, standard deviation, minimum & maximum sensor values\n",
    "feature_column=[]\n",
    "for i in sensor_data.columns[1:-1]:\n",
    "    feature_column.append('s{0}_median'.format(i[7:])) #to select sensor number\n",
    "    feature_column.append('s{0}_mean'.format(i[7:]))\n",
    "    feature_column.append('s{0}_std'.format(i[7:]))\n",
    "    feature_column.append('s{0}_min'.format(i[7:]))\n",
    "    feature_column.append('s{0}_max'.format(i[7:]))\n",
    "    \n",
    "feature_column.append('machine_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39a005",
   "metadata": {},
   "source": [
    "Based on the provided window spacing value 'w' we can predict the failure of machine earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rolling window features\n",
    "\n",
    "w=10\n",
    "X = []\n",
    "for i in sensor_data.columns[1:]:\n",
    "    \n",
    "    X1,X2,X3,X4,X5,X6=[],[],[],[],[],[]\n",
    "    \n",
    "    if not i =='machine_status':\n",
    "        X1.append(sensor_data[i].rolling(w).median()) #creating mean min etc for each sensor window\n",
    "        X2.append(sensor_data[i].rolling(w).mean())\n",
    "        X3.append(sensor_data[i].rolling(w).std())\n",
    "        X4.append(sensor_data[i].rolling(w).min())\n",
    "        X5.append(sensor_data[i].rolling(w).max())\n",
    "        feature_data = np.hstack([np.array(X1).reshape(-1,1),np.array(X2).reshape(-1,1),np.array(X3).reshape(-1,1),np.array(X4).reshape(-1,1),np.array(X5).reshape(-1,1)])\n",
    "    \n",
    "    else:    \n",
    "        X6.append(sensor_data[i].rolling(w).max()) # taking class label, if there is even singal failure we consider whole window as failure window.\n",
    "        feature_data=np.array(X6).reshape(-1,1)\n",
    "    \n",
    "    X.append(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0aa549",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sdata = X[0]\n",
    "for i in range(1,len(X)):\n",
    "    temp_sdata = np.hstack([temp_sdata, X[i]])\n",
    "\n",
    "sdata_df = pd.DataFrame(temp_sdata, columns=feature_column)\n",
    "sdata_df= sdata_df.loc[w-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifting window as 2w inorder to predict the failure in the given window fram \n",
    "temp_sdata1=sdata_df['machine_status'].iloc[w+w:].values\n",
    "temp_sdata2=sensor_data['timestamp'].iloc[w:-(w+w-1)].values\n",
    "sdata_df=sdata_df.iloc[:-(w+w)].copy()\n",
    "sdata_df['machine_status']=temp_sdata1\n",
    "sdata_df['timestamp']=temp_sdata2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e9445",
   "metadata": {},
   "source": [
    "# Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ef92e",
   "metadata": {},
   "source": [
    "### Identifying corelation between various sensor data:\n",
    "\n",
    "- From the head map we could see there is high relationship between sensors 14 to 26 & medium level of coorealation between 1 to 12 & 29 to 36\n",
    "-  By removing the coorelated sensor values ideally > than 0.5, we could see improvised version of data model eliminating noise & inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58932e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(25,25))\n",
    "corrmatrix = sensor_data.corr()\n",
    "cmap = sns.color_palette('Spectral_r',9,as_cmap=True)\n",
    "sns.heatmap(corrmatrix, cmap=cmap, vmax=1, vmin =-1, center=0, fmt='.2f', square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260194b",
   "metadata": {},
   "source": [
    "# Step 3: Data Modeling for Machine Learning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e370909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import  recall_score, confusion_matrix\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d132c1",
   "metadata": {},
   "source": [
    "There many machine learning algorithm available in the industry, but we must be peculiar in selecting a specific algorithm, which will be matching our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our rolling window dataframe as X data\n",
    "X = sdata_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4eb736",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "- As this is a timeseries data where the values vary over a time period cycle we consider taking older values for training & newer values for testing\n",
    "- We have only 7 failure data points we have decided to use 4 data point for train and 2 for CV and 1 for a test \n",
    "- We will use 50% data for train and 25% for each CV and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train=X.iloc[0:int((X.shape[0]*50)/100)]\n",
    "X_Cv=X.iloc[int((X.shape[0]*50)/100):int((X.shape[0]*75)/100)]\n",
    "X_Test=X.iloc[int((X.shape[0]*75)/100):]\n",
    "print('train shape:',X_Train.shape)\n",
    "print('cv shape:',X_Cv.shape)\n",
    "print('test shape:',X_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_Train['machine_status']\n",
    "X_train = X_Train.drop(['machine_status'], axis=1)\n",
    "y_cv = X_Cv['machine_status']\n",
    "X_cv = X_Cv.drop(['machine_status'], axis=1)\n",
    "y_test = X_Test['machine_status']\n",
    "X_test = X_Test.drop(['machine_status'], axis=1)\n",
    "labels = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4479c",
   "metadata": {},
   "source": [
    "## Linear Regression (Linear Machine Learning Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train[X_train.columns[0:-1]], y_train)\n",
    "regr_pred=regr.predict(X_test[X_train.columns[0:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_regr=round(regr.score(X_train[X_train.columns[0:-1]], y_train)*100,10)\n",
    "acc_regr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, regr_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.DataFrame({'Actual': y_test, 'Predicted': regr_pred})\n",
    "df_lr.plot()\n",
    "\n",
    "# sns.set_style('whitegrid')\n",
    "# sns.lmplot(x ='Actual', y ='Predicted', data = df_lr)\n",
    "# #sns.regplot(y_test,regr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8c2b1",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours ( Non-Linear Machine Learning Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "clf = knn.fit(X_train[X_train.columns[0:-1]], y_train)\n",
    "knn_y_pred = clf.predict(X_test[X_train.columns[0:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knb_model=roc_auc_score(y_test, knn_y_pred)*100\n",
    "acc_knb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = metrics.confusion_matrix(y_test, knn_y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.3%', cmap='YlGnBu',xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame() #temp dataframe\n",
    "d['time']=X_test['timestamp']\n",
    "d['true']=y_test\n",
    "d['pred']=knn_y_pred\n",
    "a=d[d['true']==0]\n",
    "x=a[a['pred']==1]\n",
    "x['time']=pd.to_datetime(x['time'])\n",
    "g=x.groupby(by=x['time'].dt.date)\n",
    "print('date of failure:',list(g.groups.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0819a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d['time']=='7/25/2018 14:00']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a567026",
   "metadata": {},
   "source": [
    "## RandomForest Classifier - Ensemble Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fa17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rclf = RandomForestClassifier(max_features='sqrt',n_jobs=-1,random_state=1)\n",
    "rclf.fit(X_train[X_train.columns[0:-1]], y_train)\n",
    "rclf_y_pred = rclf.predict(X_test[X_train.columns[0:-1]])\n",
    "\n",
    "print('test confusion and recall matrix:\\n')\n",
    "cf_matrix = metrics.confusion_matrix(y_test, rclf_y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.3%', cmap='YlGnBu',xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()\n",
    "\n",
    "print('test AUC score:',roc_auc_score(y_test, rclf.predict_proba(X_test[X_train.columns[0:-1]])[:,1])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7b479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=pd.DataFrame() #temp dataframe\n",
    "d['time']=X_test['timestamp']\n",
    "d['true']=y_test\n",
    "d['pred']=clf.predict(X_test[X_train.columns[0:-1]])\n",
    "a=d[d['true']==0]\n",
    "x=a[a['pred']==1]\n",
    "x['time']=pd.to_datetime(x['time'])\n",
    "g=x.groupby(by=x['time'].dt.date)\n",
    "print('date of failure:',list(g.groups.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all FP points of date:',list(g.groups.keys())[0])\n",
    "g.get_group(list(g.groups.keys())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba51a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['pred'][d['time']=='7/25/2018 13:50']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1741d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
